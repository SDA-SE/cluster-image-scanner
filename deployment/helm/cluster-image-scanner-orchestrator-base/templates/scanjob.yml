apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: scan-image-job-template
  namespace: {{ .Release.Namespace }}
spec:
  onExit: exit-handler
  activeDeadlineSeconds: {{ .Values.scanjob.activeDeadlineSeconds }}
  artifactRepositoryRef:
    configMap: artifact-repositories
    key: default-v1
  ttlStrategy:
    {{- toYaml .Values.scanjob.ttlStrategy | nindent 4 }}
  retryStrategy:
    {{- toYaml .Values.scanjob.retryStrategy | nindent 4 }}
  entrypoint: main # Entry point for job execution
  inputs:
    parameters:
      - name: REGISTRY_SECRET
      - name: DEPENDENCY_SCAN_CM
      - name: DEFECTDOJO_CM
      - name: DEFECTDOJO_SECRETS
      - name: SCAN_ID
      - name: team
      - name: environment
      - name: namespace
      - name: scm_source_branch
      - name: image
      - name: image_id
      - name: appversion
      - name: appname
      - name: slack
      - name: is_scan_lifetime
      - name: is_scan_baseimage_lifetime
      - name: is_scan_distroless
      - name: is_scan_malware
      - name: is_scan_runasroot
      - name: scan_lifetime_max_days
      - name: is_scan_new_version
      - name: is_scan_dependency_track
      - name: new_version_image_filter
      - name: imageRegistryBase
      - name: scanjobEnvParameter
      - name: containerType
      - name: slackTokenSecretName
      - name: errorTargets
  #      - name: engagementTags
  templates:
    - name: main
      dag:
        tasks:
          - name: imagefetcher
            template: imagefetcher
          - name: sbom-generation
            depends: imagefetcher
            template: sbom-generation
            when: "{{ "{{" }} workflow.parameters.is_scan_dependency_track{{ "}}" }} == true"
          - name: dtrack
            depends: sbom-generation
            template: dtrack
            when: "{{ "{{" }} workflow.parameters.is_scan_dependency_track{{ "}}" }} == true"
          - name: dtrack-notify-thresholds
            depends: dtrack
            template: dtrack-notify-thresholds
            when: "{{ "{{" }} workflow.parameters.is_scan_dependency_track{{ "}}" }} == true"
          - name: dtrack-dd-upload
            depends: dtrack-notify-thresholds
            template: dtrack-dd-upload
            arguments:
              parameters:
                - name: dependency-track-notification-alerts
                  value: "{{ "{{" }} tasks.dtrack-notify-thresholds.outputs.parameters.dependency-track-notification-alerts {{ "}}" }}"
            when: "{{ "{{" }} workflow.parameters.is_scan_dependency_track {{ "}}" }} == true"
          - name: distroless
            depends: imagefetcher
            template: distroless
            when: "{{ "{{" }} workflow.parameters.is_scan_distroless {{ "}}" }} == true"
          - name: lifetime
            depends: imagefetcher
            template: lifetime
            when: "{{ "{{" }} workflow.parameters.is_scan_lifetime {{ "}}" }} == true"
          - name: base-lifetime
            depends: imagefetcher
            template: base-lifetime
            when: "{{ "{{" }} workflow.parameters.is_scan_baseimage_lifetime {{ "}}" }} == true"
          - name: runasroot
            depends: imagefetcher
            template: runasroot
            when: "{{ "{{" }} workflow.parameters.is_scan_runasroot {{ "}}" }} == true"
          - name: malware
            depends: imagefetcher
            template: malware
            when: "{{ "{{" }} workflow.parameters.is_scan_malware {{ "}}" }} == true"
          - name: new-version
            depends: imagefetcher
            template: new-version
            when: "{{ "{{" }} workflow.parameters.is_scan_new_version {{ "}}" }} == true"
          - name: col-gen-finds # shortened from 'collect-generic-findings'
            depends: (distroless.Succeeded || lifetime.Succeeded || base-lifetime.Succeeded || runasroot.Succeeded || malware.Succeeded || new-version.Succeeded)
            template: col-gen-finds
          - name: gen-dd-upload # shortened from 'generic-dd-upload'
            depends: col-gen-finds
            template: gen-dd-upload
            arguments:
              artifacts:
                - name: results-generic-findings
                  from: "{{ "{{" }} tasks.col-gen-finds.outputs.artifacts.results-generic-findings{{ "}}" }}"
            #when: "{{ "{{" }} distroless.Succeeded {{ "}}" }} == true || {{ "{{" }} lifetime.Succeeded {{ "}}" }} == true || {{ "{{" }} base-lifetime.Succeeded {{ "}}" }} == true || {{ "{{" }} runasroot.Succeeded {{ "}}" }} == true || malware.Succeeded || {{ "{{" }} new-version.Succeeded {{ "}}" }} == true"
          - name: aggregate
            depends: (gen-dd-upload.Succeeded || dtrack-dd-upload.Succeeded)
            template: aggregate
            arguments:
              artifacts:
                - name: results-dd-generic-test-link
                  from: "{{ "{{" }} tasks.gen-dd-upload.outputs.artifacts.results-dd-generic-test-link{{ "}}" }}"
                  optional: true
                - name: results-dd-generic-is-finding-file
                  from: "{{ "{{" }} tasks.gen-dd-upload.outputs.artifacts.is-finding-file{{ "}}" }}"
                  optional: true
                - name: results-dd-generic-findings-file
                  from: "{{ "{{" }} tasks.gen-dd-upload.outputs.artifacts.findings-file{{ "}}" }}"
                  optional: true
                - name: results-generic
                  from: "{{ "{{" }} tasks.col-gen-finds.outputs.artifacts.results-generic{{ "}}" }}"
                  optional: true
                - name: results-dd-dependency-track-test-link
                  from: "{{ "{{" }} tasks.dtrack-dd-upload.outputs.artifacts.results-dd-dependency-track-test-link{{ "}}" }}"
                  optional: true
                - name: results-dd-dependency-track-is-finding-file
                  from: "{{ "{{" }} tasks.dtrack-dd-upload.outputs.artifacts.is-finding-file{{ "}}" }}"
                  optional: true
                - name: results-dd-dependency-track-findings-file
                  from: "{{ "{{" }} tasks.dtrack-dd-upload.outputs.artifacts.findings-file{{ "}}" }}"
                  optional: true

    - name: imagefetcher
      volumes:
        - name: images
          persistentVolumeClaim:
            claimName: cluster-image-scanner-images
        - name: registry-creds
          secret:
            secretName: "{{ "{{" }} workflow.parameters.REGISTRY_SECRET{{ "}}" }}"
        - name: tmp
          emptyDir: { }
{{- if .Values.scanjob.caBundle }}
        - name: "additional-cas"
          configMap:
            name: "scanjob-env-parameter"
{{- end }}
      script:
        resources:
          {{- toYaml .Values.scanjob.imagefetcher.resources | nindent 10 }}
        securityContext:
          {{- toYaml .Values.scanjob.securityContext | nindent 10 }}
        image: "{{ "{{" }} workflow.parameters.imageRegistryBase {{ "}}" }}/cluster-image-scanner-base:{{ "{{" }} workflow.parameters.clusterImageScannerImageTag{{ "}}" }}"
        command: [/bin/bash]
        imagePullPolicy: {{ .Values.scanjob.imagePullPolicy }}
        volumeMounts:
          - name: tmp
            mountPath: /tmp
          - name: images
            mountPath: /clusterscanner/images
            subPath: "{{ "{{" }} workflow.parameters.image_id{{ "}}" }}"
            defaultMode: 0777 # to allow the cleanup to delete the folders
          - name: registry-creds
            mountPath: /run/containers/auth.json
            subPath: auth.json
            defaultMode: 0444
{{- if .Values.scanjob.caBundle }}
          - name: additional-cas
            mountPath: /etc/ssl/certs/ca-bundle.crt
            subPath: ADDITIONAL_CAS
            defaultMode: 0444
{{- end }}
        env:
          - name: IMAGE
            value: "{{ "{{" }} workflow.parameters.image{{ "}}" }}"
          - name: IMAGE_BY_HASH
            value: "{{ "{{" }} workflow.parameters.image_id{{ "}}" }}"
        envFrom:
          - configMapRef:
              name: "{{ "{{" }} workflow.parameters.scanjobEnvParameter{{ "}}" }}"
        source: |
          # IMAGE_TAR_PATH from base image
          function cleanup {
            echo "Cleaning up"
            if [ "${lockfile_created}" == "true" ]; then
              echo "Deleting ${lock_file_path}"
              rm -rf ${lock_file_path}
            else
              echo "${lock_file_path} doesn't exists"
            fi
            rm -rf "${tmp_dir}"
          }

          trap cleanup ERR

          set -e

          if [ -z "$IMAGE_BY_HASH" ]; then
            IMAGE_BY_HASH="$IMAGE"
          fi

          echo "Initiating download of image ${IMAGE_BY_HASH}"
          set +e
          OVERRIDES=$(env | cut -d= -f1 | sort | grep -e "REGISTRY_OVERRIDE_.*_FROM")
          echo "OVERRIDES: ${OVERRIDES}"
          set -e
          if [ "${OVERRIDES}" == "" ] || [ "${REGISTRY_OVERRIDE_DEFAULT_FROM}" == "" ]; then
            echo "No registry overrides found"
          else
            while read r
            do
              _FROM="${r}"
              _TO="${r/%_FROM/_TO}"
              FROM="${!_FROM}"
              TO="${!_TO}"

              if [ -z "${TO}" ]; then
                echo "Unmatched ${r/%_FROM/_TO} for ${r}"
                exit 1
              fi

              # Validating input for sed.
              # Break out of loop if a tilde is contained.

              FROM_NEW=$(tr -d "~" <<<"${FROM}")
              if [ "$FROM_NEW" != "$FROM" ]; then
                echo "Ignoring ${_FROM} (${FROM}) because it contains a tilde"
                continue
              fi
              TO_NEW=$(tr -d "~" <<<"$TO")
              if [ "$TO_NEW" != "$TO" ]; then
                echo "Ignoring ${_TO} (${TO}) because it contains a tilde"
                continue
              fi

              IMAGE_BY_HASH_NEW=$(echo "$IMAGE_BY_HASH" | sed -e "s~${FROM}~${TO}~")
              if [ "$IMAGE_BY_HASH_NEW" != "$IMAGE_BY_HASH" ]; then
                echo "Found registry replacement:"
                echo "    Replace ${FROM}"
                echo "    with ${TO}"
                echo
                IMAGE_BY_HASH="${IMAGE_BY_HASH_NEW}"
                break
              else
                echo "Ignoring ${_FROM} (${FROM}) because it doesn't match the image URI"
              fi
            done <<<"$OVERRIDES"
          fi
          echo "Using image URI '${IMAGE_BY_HASH}'"

          echo "fetching image ${IMAGE} with hash ${IMAGE_BY_HASH}"

          IMAGE_TAR_FOLDER_PATH=/clusterscanner/images
          mkdir -p "${IMAGE_TAR_FOLDER_PATH}/" || true
          mkdir -p "${IMAGE_TAR_FOLDER_PATH}/tmp" || true
          tmp_dir=$(mktemp -d --tmpdir="/tmp")
          rm -Rf "${tmp_dir}" || true
          mkdir -p "${tmp_dir}"
          image_copy_dir=$(mktemp -d --tmpdir="${tmp_dir}")
          unpack_dir=$(mktemp -d --tmpdir="${tmp_dir}")
          config_dir=$(mktemp -d --tmpdir="${tmp_dir}")
          skopeo_tmp_dir=$(mktemp -d --tmpdir="${tmp_dir}")
          SKOPEO_COPY_PARAMETER="--tmpdir ${skopeo_tmp_dir} ${SKOPEO_COPY_PARAMETER}"
          mkdir -p "${image_copy_dir}" "${config_dir}" "${unpack_dir}" "${skopeo_tmp_dir}"
          echo "Directory /run/containers"
          ls -lah /run/containers

          echo "Checking for existing config manifest of ${IMAGE_BY_HASH}"
          # catch tagged images (which can happen if we don't know the image hash to pull by). When we have a tagged image, the image is assumed to be mutable - therefore the config.json of the image is checked, to make sure they are identical before skipping the pull process.
          timeout 30 skopeo inspect ${SKOPEO_INSPECT_PARAMETER} --config "docker://${IMAGE_BY_HASH}" | jq -cMS 'def recursively(f): . as $in | if type == "object" then reduce keys_unsorted[] as $key ( {}; . + { ($key):  ($in[$key] | recursively(f)) } ) elif type == "array" then map( recursively(f) ) | f else . end; . | recursively(sort)' > "${config_dir}/config.json"
          ls -la "${config_dir}/config.json"

          check_and_handle_image_exists() {
            if [[ -f "${IMAGE_TAR_FOLDER_PATH}/config.json" ]] && diff -qs "${config_dir}/config.json" "${IMAGE_TAR_FOLDER_PATH}/config.json" && [ -f ${IMAGE_TAR_FOLDER_PATH}/docker-archive-image.tar ]; then
              echo "Already got image with identical config manifest, skipping"
              # touch on folder to modify mtime, so it is not getting cleaned up for MAX_DAYS, see cleanup.yml
              touch "${IMAGE_TAR_PATH}"
              exit 0
            fi
          }
          check_and_handle_image_exists

          check_creation_date() {
              # Check if the file exists
              if [ ! -f "$1" ]; then
                  echo "File does not exist."
                  return 2
              fi

              # Get the creation time of the file in seconds since epoch
              creation_time=$(stat -c %Y "$1")

              # Get the current time in seconds since epoch
              current_time=$(date +%s)

              # Calculate the difference in seconds
              time_diff=$((current_time - creation_time))

              # Check if the file was created more than 60 minutes ago
              if [ "$time_diff" -gt 3600 ]; then
                  return 0
              else
                  return 1
              fi
          }

          lock_file_path="${IMAGE_TAR_FOLDER_PATH}/image-download.lock"
          lock_wait=180
          for ((i=1; i<=lock_wait; i++)); do
            if [ -f "${lock_file_path}" ]; then
              echo "${lock_file_path} exists"
              if [ "$(check_creation_date "${lock_file_path}")" == "0" ]; then
                echo "The file ${lock_file_path} was created more than 60 minutes ago, re-creating lock file and downloading"
                break
              else
                echo "The file ${lock_file_path} was created within the last 60 minutes, waiting."
                sleep 15
              fi
            else
              echo "${lock_file_path} does NOT exists"
              break
            fi
          done
          check_and_handle_image_exists

          echo "Downloading image ${IMAGE_BY_HASH} to ${image_copy_dir}"
          rm -f ${lock_file_path}
          touch ${lock_file_path}
          echo "Lockfile ${lock_file_path} created"
          export lockfile_created="true"

          skopeo copy ${SKOPEO_COPY_PARAMETER} "docker://${IMAGE_BY_HASH}" "dir:${image_copy_dir}/"
          rm -Rf ${IMAGE_TAR_FOLDER_PATH}/docker-archive-image.tar || true
          skopeo copy ${SKOPEO_COPY_PARAMETER} "docker://${IMAGE_BY_HASH}" "docker-archive:${IMAGE_TAR_FOLDER_PATH}/docker-archive-image.tar"
          layers=$(jq -r '.layers' "${image_copy_dir}/manifest.json")
          if [ "${layers}" != "null" ] && [ "${layers}" != "" ]; then
            extractionCommand=".layers | .[].digest"
          elif [ "$(jq -r '.fsLayers' "${image_copy_dir}/manifest.json")" != "null" ] && [ "$(jq -r '.fsLayers' "${image_copy_dir}/manifest.json")" != "null" ]; then
            extractionCommand=".fsLayers | .[].blobSum"
          else
            echo "Could NOT find layers to unpack"
            exit 2
          fi
          for l in $(jq -r "$extractionCommand" "${image_copy_dir}/manifest.json" | sed -e "s/^sha256://g"); do
              echo "Extracting blob ${l}"
              tar --exclude "/dev/" --mode='a+rw' --no-acls --no-selinux --no-xattrs --no-overwrite-dir --owner=clusterscanner --group=clusterscanner -mxzf "${image_copy_dir}/${l}" -C "${unpack_dir}" || true # TODO scan somehow dev
          done
          echo "Changing directory permissions"
          find "${unpack_dir}" -type d -exec chmod 755 {} +
          echo "Changing file permissions"
          find "${unpack_dir}" -type f -exec chmod 644 {} +
          cd "${unpack_dir}"

          echo "Packing image to ${IMAGE_TAR_FOLDER_PATH}"
          tar -cf "${IMAGE_TAR_PATH}" ./* || exit 1
          echo "Size of ${IMAGE_TAR_PATH}"
          ls -lah ${IMAGE_TAR_PATH}
          echo "Copying manifest and config file"
          cp "${image_copy_dir}/manifest.json" "${IMAGE_TAR_FOLDER_PATH}/manifest.json"
          rm -f "${IMAGE_TAR_FOLDER_PATH}/config.json" || true # in case an other fetcher runs in parallel
          cp "${config_dir}/config.json" "${IMAGE_TAR_FOLDER_PATH}/config.json"

          cleanup


    - name: sbom-generation
      volumes:
        - name: images
          persistentVolumeClaim:
            claimName: cluster-image-scanner-images
            readOnly: true
        - name: scandata
          persistentVolumeClaim:
            claimName: cluster-image-scanner-scandata
        - name: tmp
          emptyDir: { }
      container:
        resources:
          {{- toYaml .Values.scanjob.sbomgeneration.resources | nindent 10 }}
        securityContext:
          {{- toYaml .Values.scanjob.securityContext | nindent 10 }}
        image: "{{ "{{" }} workflow.parameters.imageRegistryBase {{ "}}" }}/cluster-image-scanner-scan-syft:{{ "{{" }} workflow.parameters.clusterImageScannerImageTag{{ "}}" }}"
        command: ["/clusterscanner/entrypoint.bash"]
        args: [
          "scan",
          "docker-archive:/clusterscanner/images/docker-archive-image.tar",
          "--output",
          "cyclonedx-json=/clusterscanner/data/bom.json"
        ]
        env:
          - name: IS_SCAN
            value: "{{ "{{" }} workflow.parameters.is_scan_dependency_track{{ "}}" }}"
        envFrom:
          - configMapRef:
              name: "{{ "{{" }} workflow.parameters.scanjobEnvParameter{{ "}}" }}"
        imagePullPolicy: {{ .Values.scanjob.imagePullPolicy }}
        volumeMounts:
          - name: tmp
            mountPath: /tmp
          - name: images
            mountPath: /clusterscanner/images
            subPath: "{{ "{{" }} workflow.parameters.image_id{{ "}}" }}"
            readOnly: true
          - name: scandata
            mountPath: /clusterscanner/data
            subPath: "results/{{ "{{" }} workflow.parameters.image_id {{ "}}" }}/sbom"

    - name: dtrack
      volumes:
        - name: scandata
          persistentVolumeClaim:
            claimName: cluster-image-scanner-scandata
        - name: tmp
          emptyDir: { }
      script:
        resources:
          {{- toYaml .Values.scanjob.scanDependencyTrack.resources | nindent 10 }}
        securityContext:
          {{- toYaml .Values.scanjob.securityContext | nindent 10 }}
        image: "{{ "{{" }} workflow.parameters.imageRegistryBase {{ "}}" }}/cluster-image-scanner-base:{{ "{{" }} workflow.parameters.clusterImageScannerImageTag{{ "}}" }}"
        command: [/bin/bash]
        imagePullPolicy: {{ .Values.scanjob.imagePullPolicy }}
        env:
          - name: IS_SCAN
            value: "{{ "{{" }} workflow.parameters.is_scan_dependency_track{{ "}}" }}"
          - name: APP_NAME
            value: "{{ "{{" }} workflow.parameters.appname{{ "}}" }}"
          - name: APP_VERSION
            value: "{{ "{{" }} workflow.parameters.appversion{{ "}}" }}"
          - name: IMAGE
            value: "{{ "{{" }} workflow.parameters.image{{ "}}" }}"
          - name: IMAGE_ID
            value: "{{ "{{" }} workflow.parameters.image{{ "}}" }}"
          - name: DD_BRANCH_NAME
            value: "{{ "{{" }} workflow.parameters.image{{ "}}" }}"
          - name: NAMESPACE
            value: "{{ "{{" }} workflow.parameters.namespace{{ "}}" }}"
          - name: ENVIRONMENT
            value: "{{ "{{" }} workflow.parameters.environment{{ "}}" }}"
          - name: TEAM
            value: "{{ "{{" }} workflow.parameters.team{{ "}}" }}"
        envFrom:
          - secretRef:
              name: "dependency-track"
          - configMapRef:
              name: "{{ "{{" }} workflow.parameters.scanjobEnvParameter{{ "}}" }}"
          - configMapRef:
              name: "dependency-track"
        volumeMounts:
          - name: tmp
            mountPath: /tmp
          - name: scandata
            mountPath: /clusterscanner/data
            subPath: "results/{{ "{{" }} workflow.parameters.image_id {{ "}}" }}/sbom"
        source: |
          set -e
          if [ "${IS_SCAN}" != "true" ]; then
            echo "Dependency Track scan is disabled"
            exit 0
          fi

          source ./scan-common.bash
          parse_and_set_image_variables
          echo "ImageName ${IMAGE_NAME}"
          PROJECT_NAME=$(echo "${DEPENDENCY_TRACK_PRODUCT_NAME_TEMPLATE}" | sed "s~###ENVIRONMENT###~${ENVIRONMENT}~" | sed "s~###NAMESPACE###~${NAMESPACE}~" | sed "s~###APP_NAME###~${IMAGE_NAME}~" )
          echo "PROJECT_NAME: ${PROJECT_NAME}"
          bomPath="/clusterscanner/data/bom.json"
          exportFilePath="/clusterscanner/data/findings.json"
          if [ "${DEPENDENCY_TRACK_KEY}" == "" ]; then
           echo "Error: DEPENDENCY_TRACK_KEY not set"
           exit 4
          fi
          ls -la "${bomPath}"
          if ! [ -f "${bomPath}" ]; then
            echo "Could not find bom file in ${bomPath}"
            exit 5
          fi
          bomBase64=$(cat "${bomPath}" | base64 -w 0)
          echo '{ "projectName": "'${PROJECT_NAME}'", "projectVersion": "'${IMAGE_TAG}'", "autoCreate": true, "bom": "'${bomBase64}'" }' > /tmp/tmpfile
          echo "bom file:"
          cat /tmp/tmpfile
          curl -iX "PUT" \
            "${DEPENDENCY_TRACK_URL}/api/v1/bom" \
            -H 'Content-Type: application/json' \
            -H "X-API-Key: ${DEPENDENCY_TRACK_KEY}" \
            -d @/tmp/tmpfile \
            --silent \
            --http1.1 \
            --show-error \
            --output /tmp/token.json

          RESPONSE=$(head -n1 /tmp/token.json | awk '{print $2}')
          BODY=$(tail -n1 /tmp/token.json)

          if [ "${RESPONSE}" -le 200 ]; then
            token=$(jq -r '.token' <<< "${BODY}")
            echo "token: ${TOKEN}"
          else
            echo "Received HTTP code ${RESPONSE} back form DependencyTrack"
            echo "Response body: ${BODY}"
            exit 1
          fi

          counter=0
          processingPerformed="false"
          MAX_RETRIES=60
          while [ "${processingPerformed}" == "true" ]; do
           let counter=counter+1
           url="${DEPENDENCY_TRACK_URL}/api/v1/bom/token/${token}"
           echo "Fetching $url"
           processingPerformed=$(curl ${url} \
            --header 'Accept: application/json' \
            -H "X-API-Key: ${DEPENDENCY_TRACK_KEY}" \
            --silent \
            --show-error \
           | jq '.processing')
           echo "Processing status '${processingPerformed}' from Dependency Track"
           if [ ${counter} -gt ${MAX_RETRIES} ]; then
             echo "ERROR Reached maximum retries of ${MAX_RETRIES}, stop trying to get processing status"
             exit 2
           fi
           sleep 2
          done
          echo "GET ${DEPENDENCY_TRACK_URL}/api/v1/project?name=${PROJECT_NAME}&.."
          nameParameterUrlEncoded=$(printf %s "${PROJECT_NAME}" | jq -sRr @uri)
          curl "${DEPENDENCY_TRACK_URL}/api/v1/project?name=${nameParameterUrlEncoded}" \
           --silent \
           --show-error \
           --header 'Accept: application/json' \
           -H "X-API-Key: ${DEPENDENCY_TRACK_KEY}" \
           --output /tmp/project.json

          echo "/tmp/project.json"
          cat /tmp/project.json
          cat /tmp/project.json | jq -r '.[] | select(.version=="'${IMAGE_TAG}'") | .uuid' > /tmp/project-uuid.txt

          export UUID=$(cat /tmp/project-uuid.txt)
          if [ "${UUID}" == "" ]; then
           echo "Error: UUID has the unexpected value '${UUID}'"
           exit 1
          fi
          if [ $(echo "${UUID}" | wc -l) -ne 1 ]; then
           echo "Error: UUID '${UUID}' has unexpected newline"
           exit 3
          fi

          echo "Fetching ${DEPENDENCY_TRACK_URL}/api/v1/finding/project/${UUID}/export"




          #purl="^(?:(?!pkg:deb).)*$"
          #purlEncodedValue=$(printf %s "${purl}" | jq -sRr @uri)
          curl "${DEPENDENCY_TRACK_URL}/api/v1/finding/project/${UUID}/export" \
           --silent \
           --show-error \
           -H "X-API-Key: ${DEPENDENCY_TRACK_KEY}" \
           --output ${exportFilePath}
          exit 0
          ## In development: Check for new package version
          DEFAULT_NPM_BASE_URL="https://registry.npmjs.org";
          NPM_API_LATEST_URL="/-/package/%s/dist-tags";
          # http://localhost:8071/api/v1/component/project/bc33ac48-fb26-4142-99c3-96fdb0f07066?searchText=&sortOrder=asc&pageSize=100&pageNumber=1
          # jq | '.[]'
          # foreach
          if  [ repositoryType == "NPM" ]; then
            packageName="abab"
            version="1.0.0"

            packageNameEncoded=$(printf %s "${packageName}" | jq -sRr @uri)

            times=$(curl --silent  "${DEFAULT_NPM_BASE_URL}/${packageNameEncoded}" | jq -r ".time")
            next=false;
            for listedVersion in $versions; do
              if [ "${next}" == "true" ];then
                break;
              fi;
              #echo "${version} == ${listedVersion}";
              if [ "${version}" == "${listedVersion}" ]; then
                next="true";
              fi
            done

            publishedDate=$(curl --silent  "${DEFAULT_NPM_BASE_URL}/${packageNameEncoded}" | jq -r ".time[\"${listedVersion}\"]")

          fi

    - name: dtrack-notify-thresholds
      volumes:
        - name: tmp
          emptyDir: { }
      outputs:
        parameters:
          - name: dependency-track-notification-alerts
            valueFrom:
              path: /tmp/output.json
      script:
        resources:
          {{- toYaml .Values.scanjob.dtrackNotificationThresholds.resources | nindent 10 }}
        securityContext:
          {{- toYaml .Values.scanjob.securityContext | nindent 10 }}
        image: "{{ "{{" }} workflow.parameters.imageRegistryBase {{ "}}" }}/cluster-image-scanner-base:{{ "{{" }} workflow.parameters.clusterImageScannerImageTag{{ "}}" }}"
        command: [/bin/bash]
        imagePullPolicy: {{ .Values.scanjob.imagePullPolicy }}
        env:
          - name: CONTAINER_TYPE
            value: "{{ "{{" }} workflow.parameters.containerType{{ "}}" }}"
          - name: DEPENDENCY_TRACK_NOTIFICATION_THRESHOLDS_APPLICATION
            value: '{
              "maven": {"critical": 1, "high": 1, "medium": 100},
              "golang": {"critical": 1, "high": 1, "medium": 100},
              "npm": {"critical": 1, "high": 1, "medium": 100},
              "deb": {"critical": 8, "high": 20, "medium": 100},
              "rpm": {"critical": 8, "high": 20, "medium": 100},
              "pypi": {"critical": 8, "high": 20, "medium": 100},
              "alpine": {"critical": 8, "high": 20, "medium": 100}}'
          - name: DEPENDENCY_TRACK_NOTIFICATION_THRESHOLDS_THIRD_PARTY
            value: '{
              "maven": {"critical": 99, "high": 999, "medium": 9999},
              "golang": {"critical": 99, "high": 999, "medium": 9999},
              "pypi": {"critical": 99, "high": 999, "medium": 9999},
              "npm": {"critical": 99, "high": 9999, "medium": 9999},
              "deb": {"critical": 30, "high": 100, "medium": 9999},
              "rpm": {"critical": 30, "high": 100, "medium": 9999},
              "alpine": {"critical": 30, "high": 100, "medium": 9999}}'
        envFrom:
          - configMapRef:
              name: "{{ "{{" }} workflow.parameters.scanjobEnvParameter{{ "}}" }}"
        volumeMounts:
          - name: tmp
            mountPath: /tmp
        source: |
          set -e

          TARGET=/tmp/output.json

          if [ "${CONTAINER_TYPE}" == "application" ]; then
            CONTENT="${DEPENDENCY_TRACK_NOTIFICATION_THRESHOLDS_APPLICATION}"
          elif [ "${CONTAINER_TYPE}" == "third-party" ]; then
            CONTENT="${DEPENDENCY_TRACK_NOTIFICATION_THRESHOLDS_THIRD_PARTY}"
          else
            CONTENT="${DEPENDENCY_TRACK_NOTIFICATION_THRESHOLDS_APPLICATION}"
          fi
          echo "${CONTENT}" > ${TARGET}
          echo "${CONTENT}"

    - name: dtrack-dd-upload
      volumes:
        - name: scandata
          persistentVolumeClaim:
            claimName: cluster-image-scanner-scandata
        - name: tmp
          emptyDir: { }
      inputs:
        parameters:
          - name: dependency-track-notification-alerts
      outputs:
        artifacts:
          - name: results-dd-dependency-track-test-link
            path: /tmp/defectDojoTestLink.txt
            optional: true
          - name: is-finding-file
            path: /tmp/isFinding
            optional: true
          - name: findings-file
            path: /tmp/findings.json
            optional: true
      container:
        resources:
          {{- toYaml .Values.scanjob.resultsUpload.resources | nindent 10 }}
        securityContext:
          {{- toYaml .Values.scanjob.securityContext | nindent 10 }}
        image: "{{ "{{" }} workflow.parameters.imageRegistryBase {{ "}}" }}/defectdojo-client:3.1.209"
        volumeMounts:
          - name: tmp
            mountPath: /tmp
          - name: scandata
            mountPath: /tmp/dependency-track-results
            subPath: "results/{{ "{{" }} workflow.parameters.image_id {{ "}}" }}/sbom"
            readOnly: true
        imagePullPolicy: {{ .Values.scanjob.imagePullPolicy }}
        command: [ "java", "-cp", "@/app/jib-classpath-file", "org.sdase.Main" ]
        envFrom:
          - configMapRef:
              name: "{{ "{{" }} workflow.parameters.DEFECTDOJO_CM{{ "}}" }}"
          - configMapRef:
              name: "{{ "{{" }} workflow.parameters.scanjobEnvParameter{{ "}}" }}"
          - secretRef:
              name: "{{ "{{" }} workflow.parameters.DEFECTDOJO_SECRETS{{ "}}" }}"
        env:
          - name: APP_NAME
            value: "{{ "{{" }} workflow.parameters.appname{{ "}}" }}"
          - name: DD_BRANCH_NAME
            value: "{{ "{{" }} workflow.parameters.image{{ "}}" }}"
          - name: DD_REPORT_TYPE
            value: "Dependency Track Finding Packaging Format (FPF) Export"
          - name: NAMESPACE
            value: "{{ "{{" }} workflow.parameters.namespace{{ "}}" }}"
          - name: ENVIRONMENT
            value: "{{ "{{" }} workflow.parameters.environment{{ "}}" }}"
          - name: DD_TEAM
            value: "{{ "{{" }} workflow.parameters.team{{ "}}" }}"
          - name: DD_REPORT_PATH
            value: "/tmp/dependency-track-results/findings.json"
          - name: EXIT_CODE_ON_FINDING
            value: "0"
          - name: EXIT_CODE_ON_MISSING_REPORT
            value: "0" # make the job successful
          - name: DD_MINIMUM_SEVERITY # notify for each unhandled vulnerability of the given severity (or higher)
            value: "High"
          - name: DEPENDENCY_TRACK_UNHANDLED_PACKAGES_MINIMUM_TO_ALERT
            value: "{{ "{{" }} inputs.parameters.dependency-track-notification-alerts{{ "}}" }}"

    - name: distroless
      volumes:
        - name: images
          persistentVolumeClaim:
            claimName: cluster-image-scanner-images
            readOnly: true
        - name: scandata
          persistentVolumeClaim:
            claimName: cluster-image-scanner-scandata
        - name: tmp
          emptyDir: { }
      container:
        resources:
          {{- toYaml .Values.scanjob.scanDistroless.resources | nindent 10 }}
        securityContext:
          {{- toYaml .Values.scanjob.securityContext | nindent 10 }}
        image: "{{ "{{" }} workflow.parameters.imageRegistryBase {{ "}}" }}/cluster-image-scanner-scan-distroless:{{ "{{" }} workflow.parameters.clusterImageScannerImageTag{{ "}}" }}"
        command: ["/clusterscanner/entrypoint.bash"]
        imagePullPolicy: {{ .Values.scanjob.imagePullPolicy }}
        volumeMounts:
          - name: tmp
            mountPath: /tmp
          - name: images
            mountPath: /clusterscanner/images
            subPath: "{{ "{{" }} workflow.parameters.image_id{{ "}}" }}"
            readOnly: true
          - name: scandata
            mountPath: /clusterscanner/data
            subPath: "results/{{ "{{" }} workflow.parameters.image_id {{ "}}" }}/generic/distroless"
        env:
          - name: IS_SCAN
            value: "{{ "{{" }} workflow.parameters.is_scan_distroless{{ "}}" }}"
          - name: IMAGE_BY_HASH
            value: "{{ "{{" }} workflow.parameters.image_id{{ "}}" }}"
        envFrom:
          - configMapRef:
              name: "{{ "{{" }} workflow.parameters.scanjobEnvParameter{{ "}}" }}"

    - name: lifetime
      volumes:
        - name: scandata
          persistentVolumeClaim:
            claimName: cluster-image-scanner-scandata
        - name: registry-creds
          secret:
            secretName: "{{ "{{" }} workflow.parameters.REGISTRY_SECRET{{ "}}" }}"
        - name: tmp
          emptyDir: { }
      container:
        resources:
          {{- toYaml .Values.scanjob.scanLifetime.resources | nindent 10 }}
        securityContext:
          {{- toYaml .Values.scanjob.securityContext | nindent 10 }}
        image: "{{ "{{" }} workflow.parameters.imageRegistryBase {{ "}}" }}/cluster-image-scanner-scan-lifetime:{{ "{{" }} workflow.parameters.clusterImageScannerImageTag{{ "}}" }}"
        imagePullPolicy: {{ .Values.scanjob.imagePullPolicy }}
        command: ["/clusterscanner/entrypoint.bash"]
        volumeMounts:
          - name: tmp
            mountPath: /tmp
          - name: scandata
            mountPath: /clusterscanner/data
            subPath: "results/{{ "{{" }} workflow.parameters.image_id {{ "}}" }}/generic/lifetime"
          - name: registry-creds
            mountPath: /run/containers/auth.json
            subPath: auth.json
            defaultMode: 0444
        env:
          - name: IMAGE_BY_HASH
            value: "{{ "{{" }} workflow.parameters.image_id{{ "}}" }}"
          - name: MAX_IMAGE_LIFETIME_IN_DAYS
            value: "{{ "{{" }} workflow.parameters.scan_lifetime_max_days{{ "}}" }}"
          - name: IS_SCAN
            value: "{{ "{{" }} workflow.parameters.is_scan_lifetime{{ "}}" }}"
        envFrom:
          - configMapRef:
              name: "{{ "{{" }} workflow.parameters.scanjobEnvParameter{{ "}}" }}"

    - name: base-lifetime
      volumes:
        - name: scandata
          persistentVolumeClaim:
            claimName: cluster-image-scanner-scandata
        {{ - if .Values.scanjob.caBundle }}
        - name: "additional-cas"
          configMap:
            name: "scanjob-env-parameter"
        {{ - end }}
        - name: tmp
          emptyDir: { }
        - name: registry-creds
          secret:
            secretName: "{{ "{{" }} workflow.parameters.REGISTRY_SECRET{{ "}}" }}"
      container:
        resources:
          {{- toYaml .Values.scanjob.scanLifetimeBaseImage.resources | nindent 10 }}
        securityContext:
          {{- toYaml .Values.scanjob.securityContext | nindent 10 }}
        image: "{{ "{{" }} workflow.parameters.imageRegistryBase {{ "}}" }}/cluster-image-scanner-scan-lifetime:{{ "{{" }} workflow.parameters.clusterImageScannerImageTag{{ "}}" }}"
        imagePullPolicy: {{ .Values.scanjob.imagePullPolicy }}
        command: ["/clusterscanner/entrypoint.bash"]
        volumeMounts:
          - name: tmp
            mountPath: /tmp
          {{ - if .Values.scanjob.caBundle }}
          - name: additional-cas
            mountPath: /etc/ssl/certs/ca-bundle.crt
            subPath: ADDITIONAL_CAS
            defaultMode: 0444
          {{ - end }}
          - name: scandata
            mountPath: /clusterscanner/data
            subPath: "results/{{ "{{" }} workflow.parameters.image_id {{ "}}" }}/generic/baseimage-lifetime"
          - name: registry-creds
            mountPath: /run/containers/auth.json
            subPath: auth.json
            defaultMode: 0444
        env:
          - name: IMAGE_BY_HASH
            value: "{{ "{{" }} workflow.parameters.image_id{{ "}}" }}"
          - name: MAX_IMAGE_LIFETIME_IN_DAYS
            value: "{{ "{{" }} workflow.parameters.scan_lifetime_max_days{{ "}}" }}"
          - name: IS_SCAN
            value: "{{ "{{" }} workflow.parameters.is_scan_baseimage_lifetime{{ "}}" }}"
          - name: MODULE_NAME
            value: "scan-baseimage-lifetime"
          - name: IS_BASE_IMAGE_LIFETIME_SCAN
            value: "true"
        envFrom:
          - configMapRef:
              name: "{{ "{{" }} workflow.parameters.scanjobEnvParameter{{ "}}" }}"

    - name: runasroot
      volumes:
        - name: registry-creds
          secret:
            secretName: "{{ "{{" }} workflow.parameters.REGISTRY_SECRET{{ "}}" }}"
        - name: scandata
          persistentVolumeClaim:
            claimName: cluster-image-scanner-scandata
        - name: tmp
          emptyDir: { }
      container:
        resources:
          {{- toYaml .Values.scanjob.scanRunAsRoot.resources | nindent 10 }}
        securityContext:
          {{- toYaml .Values.scanjob.securityContext | nindent 10 }}
        image: "{{ "{{" }} workflow.parameters.imageRegistryBase {{ "}}" }}/cluster-image-scanner-scan-runasroot:{{ "{{" }} workflow.parameters.clusterImageScannerImageTag{{ "}}" }}"
        imagePullPolicy: {{ .Values.scanjob.imagePullPolicy }}
        command: ["/clusterscanner/entrypoint.bash"]
        volumeMounts:
          - name: tmp
            mountPath: /tmp
          - name: scandata
            mountPath: /clusterscanner/data
            subPath: "results/{{ "{{" }} workflow.parameters.image_id {{ "}}" }}/generic/runasroot"
          - name: registry-creds
            mountPath: /run/containers/auth.json
            subPath: auth.json
            defaultMode: 0444
        env:
          - name: IMAGE_BY_HASH
            value: "{{ "{{" }} workflow.parameters.image_id{{ "}}" }}"
          - name: IS_SCAN
            value: "{{ "{{" }} workflow.parameters.is_scan_runasroot{{ "}}" }}"
        envFrom:
          - configMapRef:
              name: "{{ "{{" }} workflow.parameters.scanjobEnvParameter{{ "}}" }}"

    - name: new-version
      volumes:
        - name: registry-creds
          secret:
            secretName: "{{ "{{" }} workflow.parameters.REGISTRY_SECRET{{ "}}" }}"
        - name: scandata
          persistentVolumeClaim:
            claimName: cluster-image-scanner-scandata
        - name: tmp
          emptyDir: { }
      container:
        resources:
          {{- toYaml .Values.scanjob.scanNewVersion.resources | nindent 10 }}
        securityContext:
          {{- toYaml .Values.scanjob.securityContext | nindent 10 }}
        image: "{{ "{{" }} workflow.parameters.imageRegistryBase {{ "}}" }}/cluster-image-scanner-scan-new-version:{{ "{{" }} workflow.parameters.clusterImageScannerImageTag{{ "}}" }}"
        imagePullPolicy: {{ .Values.scanjob.imagePullPolicy }}
        command: ["/clusterscanner/entrypoint.bash"]
        volumeMounts:
          - name: tmp
            mountPath: /tmp
          - name: scandata
            mountPath: /clusterscanner/data
            subPath: "results/{{ "{{" }} workflow.parameters.image_id {{ "}}" }}/generic/new-version"
          - name: registry-creds
            mountPath: /run/containers/auth.json
            subPath: auth.json
            defaultMode: 0444
        env:
          - name: IMAGE_BY_HASH
            value: "{{ "{{" }} workflow.parameters.image_id{{ "}}" }}"
          - name: IMAGE
            value: "{{ "{{" }} workflow.parameters.image{{ "}}" }}"
          - name: IS_SCAN
            value: "{{ "{{" }} workflow.parameters.is_scan_new_version{{ "}}" }}"
          - name: IMAGE_SCAN_POSITIVE_FILTER
            value: "{{ "{{" }} workflow.parameters.new_version_image_filter{{ "}}" }}"
        envFrom:
          - configMapRef:
              name: "{{ "{{" }} workflow.parameters.scanjobEnvParameter{{ "}}" }}"

    - name: malware
      volumes:
        - name: images
          persistentVolumeClaim:
            claimName: cluster-image-scanner-images
            readOnly: true
        - name: registry-creds
          secret:
            secretName: "{{ "{{" }} workflow.parameters.REGISTRY_SECRET{{ "}}" }}"
        - name: scandata
          persistentVolumeClaim:
            claimName: cluster-image-scanner-scandata
        - name: tmp
          emptyDir: { }
      container:
        resources:
          {{- toYaml .Values.scanjob.scanMalware.resources | nindent 10 }}
        securityContext:
          {{- toYaml .Values.scanjob.securityContext | nindent 10 }}
        image: "{{ "{{" }} workflow.parameters.imageRegistryBase {{ "}}" }}/cluster-image-scanner-scan-malware:{{ "{{" }} workflow.parameters.clusterImageScannerImageTag{{ "}}" }}"
        imagePullPolicy: Always # to have up to date signatures
        command: ["/clusterscanner/entrypoint.bash"]
        volumeMounts:
          - name: tmp
            mountPath: /tmp
          - name: images
            mountPath: /clusterscanner/images
            subPath: "{{ "{{" }} workflow.parameters.image_id{{ "}}" }}"
            readOnly: true
          - name: scandata
            mountPath: /clusterscanner/data
            subPath: "results/{{ "{{" }} workflow.parameters.image_id {{ "}}" }}/generic/malware"
          - name: registry-creds
            mountPath: /run/containers/auth.json
            subPath: auth.json
            defaultMode: 0444
        env:
          - name: IMAGE_BY_HASH
            value: "{{ "{{" }} workflow.parameters.image_id{{ "}}" }}"
          - name: IMAGE
            value: "{{ "{{" }} workflow.parameters.image{{ "}}" }}"
          - name: IS_SCAN
            value: "{{ "{{" }} workflow.parameters.is_scan_malware{{ "}}" }}"
        envFrom:
          - configMapRef:
              name: "{{ "{{" }} workflow.parameters.scanjobEnvParameter{{ "}}" }}"

    - name: col-gen-finds
      volumes:
        - name: scandata
          persistentVolumeClaim:
            claimName: cluster-image-scanner-scandata
            readOnly: true
        - name: tmp
          emptyDir: { }
      outputs:
        artifacts:
          - name: results-generic
            path: /tmp/result.json
          - name: results-generic-findings
            path: /tmp/findings.json
      script:
        resources:
          {{- toYaml .Values.scanjob.collectFindings.resources | nindent 10 }}
        securityContext:
          {{- toYaml .Values.scanjob.securityContext | nindent 10 }}
        image: "{{ "{{" }} workflow.parameters.imageRegistryBase {{ "}}" }}/cluster-image-scanner-base:{{ "{{" }} workflow.parameters.clusterImageScannerImageTag{{ "}}" }}"
        imagePullPolicy: {{ .Values.scanjob.imagePullPolicy }}
        volumeMounts:
          - name: tmp
            mountPath: /tmp
          - name: scandata
            mountPath: /tmp/results
            subPath: "results/{{ "{{" }} workflow.parameters.image_id {{ "}}" }}/generic"
        command: [/bin/bash]
        envFrom:
          - configMapRef:
              name: "{{ "{{" }} workflow.parameters.scanjobEnvParameter{{ "}}" }}"
        source: |
          set -e

          if [ -f /clusterscanner/scan-common.bash ]; then
              source /clusterscanner/scan-common.bash
              IMAGE="{{ "{{" }} workflow.parameters.image{{ "}}" }}"
              NAMESPACE="{{ "{{" }} workflow.parameters.namespace{{ "}}" }}"
              CLUSTER="{{ "{{" }} workflow.parameters.environment{{ "}}" }}"
              RESULTS_PATH="/tmp/results"
              FINDINGS="/tmp/findings.json"
              TMP_FINDINGS="/tmp/findings.tmp.json"
              RESULTS_FILE="/tmp/result.json"
          else
              source scan-common.bash
              IMAGE="grafana@sha256:e5a9655dabef50b04847ee75da8bb9cf46f16480117b7a1d955d5648c1d6e5ba"
              NAMESPACE="TEST"
              CLUSTER="TEST-CLUSTER"
              RESULTS_PATH="test-results/${IMAGE}"
              FINDINGS="findings.json"
              TMP_FINDINGS="findings.tmp.json"
              RESULTS_FILE="result.json"
          fi

          DATE=$(date +%Y-%m-%d)

          JSON_RESULTS=$(echo "{}" | jq -Sc '.+= {"scanResults": []}')
          find ${RESULTS_PATH}
          echo '{ "findings": [] }' > "${FINDINGS}"

          export JSON_RESULTS

          merge_result() {
            echo "Collecting $1"
            JSON_RESULT=$(jq -ScM '.' "$1" )
            echo "${JSON_RESULT}"
            JSON_RESULTS=$(jq -ScM ".scanResults += [${JSON_RESULT}]" <<< "${JSON_RESULTS}")
          }

          echo "merging results..."
          while read -r f; do merge_result "$f"; done < <(find "${RESULTS_PATH}" -iname "module_*.json")
          printf "\n\n"

          echo "Results:"
          echo "$JSON_RESULTS"

          printf "%s\n\n" "------------------------"

          echo "merging findings"
          while read -r j; do
            echo "Collecting ${j}"
            echo "checking ${j} for valid JSON:"
            jq '.' "${j}" &> /dev/null
            if [ $? -eq 0 ]; then
              echo "${j} is valid JSON"
              json=$(jq -cM '.' "$j")

              echo "Will replace placeholder IMAGE ${IMAGE} in ${j}"
              json=$(add_json_field image "$IMAGE" "$json" description)

              echo "Will replace placeholder environment in /tmp/finding.tmp"
              json=$(add_json_field cluster "$CLUSTER" "$json" description)


              echo "Will replace placeholder NAMESPACE in /tmp/finding.tmp"
              json=$(add_json_field namespace "$NAMESPACE" "$json" description)


              json=$(add_json_field date "$DATE" "$json")

              desc=$(jq '.findings[].description | to_entries | map(.value) | join("\n")' <<<"$json")
              jq --arg desc "${desc}" '.findings[].description = ($desc | fromjson)' <<<"$json" > "$TMP_FINDINGS"
              TMP=$(jq --argfile f1 "${FINDINGS}" --argfile f2 "${TMP_FINDINGS}" -n '$f1 + $f2 | .findings = $f1.findings + $f2.findings')

              if  ! jq '.' <<<"$TMP" &>/dev/null ; then
                echo "Error: cannot merge findings files into one"
                exit 2
              fi
              echo "final JSON:"
              jq '.' <<<"$TMP"
              echo "writing final JSON to ${FINDINGS}"
              echo "$TMP" > "$FINDINGS"
            else
              echo "Error: ${j} does not contain valid JSON"
              exit 2
            fi

            if ! [ -s "${j}" ]; then
              echo "Error: ${j} is empty"
              exit 3
            fi
          done < <(find ${RESULTS_PATH} -iname "*.json" ! -iname "module_*")

          echo "Writing JSON_RESULTS to ${RESULTS_FILE}"
          echo "${JSON_RESULTS}" > ${RESULTS_FILE}
          sed -i.bak "s~###DATE###~${DATE}~g" ${RESULTS_FILE}
          echo "Will replace placeholder CLUSTER in ${RESULTS_FILE}"
          sed -i.bak "s/###CLUSTER###/$CLUSTER/g" ${RESULTS_FILE}
          echo "Will replace placeholder IMAGE ${IMAGE} in ${RESULTS_FILE}"
          sed -i.bak "s~###IMAGE###~$IMAGE~g" ${RESULTS_FILE}
          echo "Will replace placeholder NAMESPACE in${RESULTS_FILE}"
          sed -i.bak "s/###NAMESPACE###/$NAMESPACE/g" ${RESULTS_FILE}

          echo "cat ${FINDINGS}"
          cat ${FINDINGS}


    - name: gen-dd-upload
      inputs:
        artifacts:
          - name: results-generic-findings
            path: /tmp/generic-findings.json
      outputs:
        artifacts:
          - name: results-dd-generic-test-link
            path: /tmp/defectDojoTestLink.txt
            optional: true
          - name: is-finding-file
            path: /tmp/isFinding
            optional: true
          - name: findings-file
            path: /tmp/findings.json
            optional: true
      volumes:
        - name: tmp
          emptyDir: { }
      container:
        resources:
          {{- toYaml .Values.scanjob.resultsDDUpload.resources | nindent 10 }}
        securityContext:
          {{- toYaml .Values.scanjob.securityContext | nindent 10 }}
        image: "{{ "{{" }} workflow.parameters.imageRegistryBase {{ "}}" }}/defectdojo-client:3.1.209"
        imagePullPolicy: {{ .Values.scanjob.imagePullPolicy }}
        command: [ "java", "-cp", "@/app/jib-classpath-file", "org.sdase.Main" ]
        envFrom:
          - configMapRef:
              name: "{{ "{{" }} workflow.parameters.DEFECTDOJO_CM{{ "}}" }}"
          - configMapRef:
              name: "{{ "{{" }} workflow.parameters.scanjobEnvParameter{{ "}}" }}"
          - secretRef:
              name: "{{ "{{" }} workflow.parameters.DEFECTDOJO_SECRETS{{ "}}" }}"
        env:
          - name: APP_NAME
            value: "{{ "{{" }} workflow.parameters.appname{{ "}}" }}"
          - name: DD_BRANCH_NAME
            value: "{{ "{{" }} workflow.parameters.image{{ "}}" }}"
          - name: DD_REPORT_TYPE
            value: "Generic Findings Import"
          - name: DD_REPORT_PATH
            value: /tmp/generic-findings.json
          - name: EXIT_CODE_ON_FINDING
            value: "0"
          - name: NAMESPACE
            value: "{{ "{{" }} workflow.parameters.namespace{{ "}}" }}"
          - name: ENVIRONMENT
            value: "{{ "{{" }} workflow.parameters.environment{{ "}}" }}"
          - name: DD_TEAM
            value: "{{ "{{" }} workflow.parameters.team{{ "}}" }}"
          - name: EXIT_CODE_ON_MISSING_REPORT
            value: "0" # make the job successful
          - name: DD_MINIMUM_SEVERITY
            value: "Medium"
        volumeMounts:
          - name: tmp
            mountPath: /tmp

    - name: aggregate
      inputs:
        artifacts:
          - name: results-dd-generic-test-link
            path: /tmp/dd-generic-test-link.txt
            optional: true
          - name: results-dd-generic-is-finding-file
            path: /tmp/isFinding-generic
            optional: true
          - name: results-dd-generic-findings-file
            path: /tmp/findings-generic.json
            optional: true
          - name: results-generic
            path: /tmp/result.json
            optional: true
          - name: results-dd-dependency-track-test-link
            path: /tmp/dd-dependency-track-test-link.txt
            optional: true
          - name: results-dd-dependency-track-is-finding-file
            path: /tmp/isFinding-dependency-track
            optional: true
          - name: results-dd-dependency-track-findings-file
            path: /tmp/findings-dependency-track.json
            optional: true
      volumes:
        - name: scandata
          persistentVolumeClaim:
            claimName: cluster-image-scanner-scandata
        - name: tmp
          emptyDir: { }
      script:
        resources:
          {{- toYaml .Values.scanjob.aggregateResults.resources | nindent 10 }}
        securityContext:
          {{- toYaml .Values.scanjob.securityContext | nindent 10 }}
        image: "{{ "{{" }} workflow.parameters.imageRegistryBase {{ "}}" }}/cluster-image-scanner-base:{{ "{{" }} workflow.parameters.clusterImageScannerImageTag{{ "}}" }}"
        imagePullPolicy: {{ .Values.scanjob.imagePullPolicy }}
        volumeMounts:
          - name: tmp
            mountPath: /tmp
          - name: scandata
            mountPath: /clusterscanner/data
            subPath: "{{ "{{" }} workflow.parameters.SCAN_ID{{ "}}" }}"
            defaultMode: 0777 # to allow the cleanup to delete the folders
        command: [/bin/bash]
        envFrom:
          - configMapRef:
              name: "{{ "{{" }} workflow.parameters.scanjobEnvParameter{{ "}}" }}"
        source: |
          set -e
          field=1
          if [ $(echo {{ "{{" }} workflow.parameters.image }} | sed 's#/.*##' | tr ':' '\n' | wc -l) -eq 1 ]; then # no port
            field=2
          fi
          IMAGE_NAME=$(echo "{{ "{{" }} workflow.parameters.image{{ "}}" }}" | cut -d: -f${field})
          IMAGE_NAME_CLEANED=$(echo "${IMAGE_NAME}" | sed -e "s#/#__#g")
          if [ $(echo {{ "{{" }} workflow.parameters.image }} | sed 's#/.*##' | tr ':' '\n' | wc -l) -eq 1 ]; then # no port
            field=2
          else
            field=3
          fi
          IMAGE_TAG=$(echo "{{ "{{" }} workflow.parameters.image{{ "}}" }}" | cut -d: -f${field})
          IMAGE_HASH=$(echo "{{ "{{" }} workflow.parameters.image_id{{ "}}" }}" | sed -e "s#/#__#g" | cut -d: -f${field})
          if ! [ -e /tmp/result.json ]; then
            echo "{}" > /tmp/result.json
          fi
          JSON_RESULT=$(cat /tmp/result.json)
          JSON_RESULT=$(echo "${JSON_RESULT}" | jq -ScM ".imageTag = \"${IMAGE_TAG}\"")
          JSON_RESULT=$(echo "${JSON_RESULT}" | jq -ScM ".imageHash = \"${IMAGE_HASH}\"")
          JSON_RESULT=$(echo "${JSON_RESULT}" | jq -ScM '.image = "{{ "{{" }} workflow.parameters.image{{ "}}" }}"')
          JSON_RESULT=$(echo "${JSON_RESULT}" | jq -ScM '.environment = "{{ "{{" }} workflow.parameters.environment{{ "}}" }}"')
          JSON_RESULT=$(echo "${JSON_RESULT}" | jq -ScM '.namespace = "{{ "{{" }} workflow.parameters.namespace{{ "}}" }}"')
          JSON_RESULT=$(echo "${JSON_RESULT}" | jq -ScM '.scm_source_branch = "{{ "{{" }} workflow.parameters.scm_source_branch{{ "}}" }}"')
          JSON_RESULT=$(echo "${JSON_RESULT}" | jq -ScM '.team = "{{ "{{" }} workflow.parameters.team{{ "}}" }}"')
          JSON_RESULT=$(echo "${JSON_RESULT}" | jq -ScM '.slack = "{{ "{{" }} workflow.parameters.slack{{ "}}" }}"')
          JSON_RESULT=$(echo "${JSON_RESULT}" | jq -ScM '.email = "{{ "{{" }} workflow.parameters.email{{ "}}" }}"')
          JSON_RESULT=$(echo "${JSON_RESULT}" | jq -ScM '.appname = "{{ "{{" }} workflow.parameters.appname{{ "}}" }}"')

          JSON_DD_DEPENDENCY_TRACK=$(echo "{\"errors\":[]}")
          isFinding=$(cat /tmp/isFinding-dependency-track) || isFinding="false"
          if [ "$isFinding" == "true" ]; then
            DD_LINK=$(cat /tmp/dd-dependency-track-test-link.txt)
            JSON_DD_DEPENDENCY_TRACK=$(echo ${JSON_DD_DEPENDENCY_TRACK} | jq -Sc ". += {\"status\": \"completed\", \"finding\": true, \"infoText\": \"Potential unhandled known vulnerabilities found in image\", \"ddLink\": \"${DD_LINK}\"}")
            if [ $(cat /tmp/findings-dependency-track.json | wc -c) -gt 5 ]; then
              echo "Starting DepCheck Aggregate"
              echo $JSON_DD_DEPENDENCY_TRACK > /tmp/dd-deptrack.json
              FILESIZE=$(stat -c%s "/tmp/findings-dependency-track.json")
              FILESIZE_LIMT=25600 # 20kb
              if [ $FILESIZE -lt $FILESIZE_LIMT ]; then
                echo "Filesize of $FILESIZE is lt $FILESIZE_LIMT for /tmp/findings-dependency-track.json"
                JSON_DD_DEPENDENCY_TRACK=$(jq '.findings += input'  /tmp/dd-deptrack.json /tmp/findings-dependency-track.json)
              else
                echo "Filesize of $FILESIZE is gt $FILESIZE_LIMT /tmp/findings-dependency-track.json"
                echo '[{ "title": "Dependency Track Finding", "description": "OWASP Dependency Track found some findings, please check DefectDojo" }]' > /tmp/findings-dependency-track-zero.json
                JSON_DD_DEPENDENCY_TRACK=$(jq '.findings += input'  /tmp/dd-deptrack.json /tmp/findings-dependency-track-zero.json)
              fi
            else
              JSON_DD_DEPENDENCY_TRACK=$(echo ${JSON_DD_DEPENDENCY_TRACK} | jq -Sc ". += {\"findings\": []}")
              echo "Warning: /tmp/findings-dependency-track.json is empty"
            fi
          else
            JSON_DD_DEPENDENCY_TRACK=$(echo ${JSON_DD_DEPENDENCY_TRACK} | jq -Sc ". += {\"status\": \"completed\", \"finding\": false, \"ddLink\": \"${DD_LINK}\", \"findings\": []}")
          fi
          JSON_DD_DEPENDENCY_TRACK=$(echo ${JSON_DD_DEPENDENCY_TRACK} | jq -Sc ". += {\"scanType\": \"Dependency Track\"}")

          echo "Starting Generic"
          JSON_DD_GENERIC=$(echo "{\"errors\":[]}" )
          JSON_DD_GENERIC=$(echo ${JSON_DD_GENERIC} | jq -Sc ". += {\"scanType\": \"Generic\"}")
          isFinding=$(cat /tmp/isFinding-generic) || isFinding="false"
          if [ "${isFinding}" == "true" ]; then
            DD_LINK=$(cat /tmp/dd-generic-test-link.txt)
            JSON_DD_GENERIC=$(echo ${JSON_DD_GENERIC} | jq -Sc ". += {\"status\": \"completed\", \"finding\": true, \"infoText\": \"Potential unhandled vulnerabilities or misconfigurations found in image\", \"ddLink\": \"${DD_LINK}\"}")
            if [ $(cat /tmp/findings-generic.json  | wc -c) -gt 5 ]; then
              echo $JSON_DD_GENERIC> /tmp/generic.json
              JSON_DD_GENERIC=$(jq '.findings += input'  /tmp/generic.json /tmp/findings-generic.json)
            else
              JSON_DD_GENERIC=$(echo ${JSON_DD_DEPENDENCY_GENERIC} | jq -Sc ". += {\"findings\": []}")
              echo "Warning: /tmp/finding-generic  is empty"
            fi
          else
            JSON_DD_GENERIC=$(echo ${JSON_DD_GENERIC} | jq -Sc ". += {\"status\": \"completed\", \"finding\": false, \"ddLink\": \"${DD_LINK}\", \"findings\": []}")
          fi
          echo "defining uploadResults"
          uploadResults="[{\"ddGenericUpload\": ${JSON_DD_GENERIC}}, {\"ddDependencyTrackUpload\": ${JSON_DD_DEPENDENCY_TRACK}}]"
          echo "uploadResults: ${uploadResults}"
          JSON_RESULT=$(echo "${JSON_RESULT}" | jq -ScM ".uploadResults += ${uploadResults}")
          DD_DEPENDENCY_TRACK_FINDING=$(echo "${JSON_RESULT}" | jq -ScM ".uploadResults[] | select(.ddDependencyTrackUpload) | .ddDependencyTrackUpload.finding")
          DD_GENERIC_FINDING=$(echo "${JSON_RESULT}" | jq -ScM ".uploadResults[] | select(.ddGenericUpload) | .ddGenericUpload.finding")
          if [ "xX${DD_GENERIC_FINDING}" == "xXtrue" ] || [ "xX${DD_DEPENDENCY_TRACK_FINDING}" == "xXtrue" ]; then
            JSON_RESULT=$(echo "${JSON_RESULT}" | jq -ScM ".notificationRequired = true")
          else
            JSON_RESULT=$(echo "${JSON_RESULT}" | jq -ScM ".notificationRequired = false")
          fi

          echo "Storing into /clusterscanner/data/{{ "{{" }} workflow.parameters.environment }}__{{ "{{" }} workflow.parameters.namespace }}__${IMAGE_NAME_CLEANED}--${IMAGE_HASH}"
          echo "${JSON_RESULT}"
          echo "${JSON_RESULT}"  > /clusterscanner/data/{{ "{{" }} workflow.parameters.environment }}__{{ "{{" }} workflow.parameters.namespace }}__${IMAGE_NAME_CLEANED}--${IMAGE_HASH}.json


    - name: exit-handler
      volumes:
        - name: tmp
          emptyDir: { }
      script:
        command: [/bin/bash]
        resources:
          {{- toYaml .Values.scanjob.exitHandler.resources | nindent 10 }}
        securityContext:
          {{- toYaml .Values.scanjob.securityContext | nindent 10 }}
        image: "{{ "{{" }} workflow.parameters.imageRegistryBase {{ "}}" }}/cluster-image-scanner-base:{{ "{{" }} workflow.parameters.clusterImageScannerImageTag{{ "}}" }}"
        imagePullPolicy: {{ .Values.scanjob.imagePullPolicy }}
        env: # TODO check for email creds
          - name: MESSAGE_TARGETS
            value: "{{ "{{" }} workflow.parameters.errorTargets{{ "}}" }}"
          - name: SLACK_CLI_TOKEN
            valueFrom:
              secretKeyRef:
                name: "{{ "{{" }} workflow.parameters.slackTokenSecretName{{ "}}" }}"
                key: SLACK_CLI_TOKEN
          - name: SLACK_MESSAGE_ENDPOINT
            value: "https://slack.com/api/chat.postMessage"
        envFrom:
          - configMapRef:
              name: "scanjob-env-parameter"
        volumeMounts:
          - name: tmp
            mountPath: /tmp
        source: |
          set -e
          if [ "${MESSAGE_TARGETS}" == "" ]; then
            echo "MESSAGE_TARGETS set, exiting"
            exit 1
          fi
          if [ "${JOB_EXECUTION_NAMESPACE}" == "" ]; then # comming from scanjob-parameter
            JOB_EXECUTION_NAMESPACE="clusterscanner"
          fi
          failures='{{ "{{" }}workflow.failures{{ "}}" }}'
          failures=$(echo "${failures:1:-1}" | sed 's#\\"#"#g')
          echo "ERROR_NOTIFICATION_IGNORE: ${ERROR_NOTIFICATION_IGNORE}"
          if [ $(echo "${failures}" | grep -c "${ERROR_NOTIFICATION_IGNORE}") -ne 0 ]; then
            echo "Skipping notifiction because it is in ERROR_NOTIFICATION_IGNORE: \"${ERROR_NOTIFICATION_IGNORE}\""
            exit 0
          fi

          echo "failures"
          echo "${failures}"
          sendMessageViaslack() {
            channel="${1}"

            message=$(echo "${failures}" | jq -r '.[] | {"type": "section","text": {"type": "mrkdwn","text": "- *name:* _ \(.displayName)_\n- *image:* _{{ "{{" }}workflow.parameters.image{{ "}}" }}_\n- *template:* _\(.templateName)_\n- *message:* _\(.message)_\n- *phase:* _\(.phase)_\n- *podName:* _\(.podName)_\n- *finishedAt:* _\(.finishedAt)_\n"}},{"type": "divider"}' | jq -s .)
            echo "{\"channel\": \"${channel}\", \"blocks\": ${message}}" > /tmp/slack-template.json
            cat /tmp/slack-template.json

            if [ "${SLACK_CLI_TOKEN}" == "" ]; then
              echo "No SLACK_CLI_TOKEN set"
              exit 2
            fi

            echo "Slack endpoint: ${SLACK_MESSAGE_ENDPOINT}"

            curl \
              -H "Content-type:application/json" \
              -H "Authorization: Bearer ${SLACK_CLI_TOKEN}" \
              -X POST \
              -d @/tmp/slack-template.json \
              "${SLACK_MESSAGE_ENDPOINT}"
          }

          functionExists() { declare -F "$1" > /dev/null; }

          if [[ "${failures}" == "" ]] || [[ "${failures}" == "[]" ]] || [[ "${failures}" == "null" ]]; then
            echo "No message, exit 0"
            exit 0
          fi

          echo "${MESSAGE_TARGETS}" |  jq -c '.[]' | while read i; do
            channel=$(echo "${i}" | jq -r '.channel')
            type=$(echo "${i}" | jq -r '.type')
            echo "Sending via ${type} to channel ${channel}"
            toCall="sendMessageVia$type"
            if ! functionExists ${toCall} ; then
              echo "Message type '${type}' doesn't exit"
              exit 1
            fi

            ${toCall} "${channel}"
          done
